% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tina_combineFeatures_optics.R
\name{tina_combineFeatures_optics}
\alias{tina_combineFeatures_optics}
\title{TINA clustering using OPTICS
Tina Is Not Alignment ;)}
\usage{
tina_combineFeatures_optics(
  featureStack,
  max.eps = 50,
  minPts = 2,
  eps.stepsize = 0.01,
  max.plots = 600,
  plot.loc = "./",
  plot.name = "feature_clusters.pdf",
  nfeats = 10000,
  dist.threads = 1
)
}
\arguments{
\item{featureStack}{feature profile matrix}

\item{max.eps}{(OPTICS) maximum epsilon value (may need adjustment, possibly related to mean dist or #' of points because they're scaled profiles?)}

\item{minPts}{(OPTICS) minimum number of points needed to define core distance}

\item{eps.stepsize}{(OPTICS) step size for assessing optimal eps. value}

\item{max.plots}{max number of plot to generate. Evenly spaced subset will be chosen to meet this requirement}

\item{plot.loc}{where the plot gets written to file}

\item{plot.name}{plot filename (example.pdf)}

\item{nfeats}{a logical value indicating whether to scale the feature values to between 0 and 1 based on the highest peak's intensity}

\item{dist.threads}{a logical value indicating whether to scale the feature values to between 0 and 1 based on the highest peak's intensity}
}
\value{
a list object containing
}
\description{
Why? 
- We can't carefully compare all features in all cases, but we can use some rougher
  comparisons to guide the process and reduce computational burden. 
How?
- distance metric is just euclidean distance squared and negated. Computed using
  parallelDist::parDist(), which multithreads according to the ncores set in 
  our params.yaml file. It's pretty damn efficient, and offers other distance
  metrics that we can pass through at some point (although euclidean makes sense).
- Clustering using density-based clustering should allow us to find local minima
  in the feature comparison landscape, where clusters represent pockets of shape
  space. These are the dominant shapes in our spectra. We want to avoid 
  overclustering, but still reduce the number of features to a set which has 
  multiple instances of each shape (e.g. reliably extracted) and smaller (so
  we do fewer match comparisons).
Why OPTICS?
- It's density-based (and handles different densities), uses few parameters, 
  it produces a hierarchical arrangement of features, and it's wicked fast.
How to optimize eps?
- Set the max to a high value, then compute the hierarchy. Scan a range of eps
  values and see how many clusters get picked. I usually see a curve with a 
  max. Since we want to avoid overclustering, choose that point as the cutoff. 
  NOTE: this only works when minPts > 1.
  
 Assumes you aligned the features in the input matrix somehow (e.g. based on their maximum peaks)
}
\details{
MTJ 2022
}
