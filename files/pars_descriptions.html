
<details>
<summary>dirs</summary>
<blockquote>
 <details>
 <summary>temp</summary>
 <blockquote>
  /Users/mjudge/Documents/ftp_ebi/pipeline_runs_new<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Local temp directory, where the timestamped run directory will be created. If the last part of this path doesn't exist, it will be created.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>lib</summary>
 <blockquote>
  /nfs/production/odonovan/nmr_staging/gissmo_ref<br>
  <details>
  <summary>description</summary>
  <blockquote>
   The local directory from where reference library files are stored.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  Top-level filepaths for the pipeline.<br>
 </blockquote>
 </details>
</blockquote>
</details>

<details>
<summary>study</summary>
<blockquote>
 <details>
 <summary>id</summary>
 <blockquote>
  MTBLS1<br>
  <details>
  <summary>description</summary>
  <blockquote>
   This is the study ID (e.g. Metabolights study ID).<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>spectrometer.frequency</summary>
 <blockquote>
  700<br>
  <details>
  <summary>description</summary>
  <blockquote>
   What spectrometer frequency were the spectra acquired at in MHz?<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  These are details about the study being analyzed - necessary for indexing results, but not checked if running locally.<br>
 </blockquote>
 </details>
</blockquote>
</details>

<details>
<summary>files</summary>
<blockquote>
 <details>
 <summary>spectral.matrix</summary>
 <blockquote>
  /nfs/production/odonovan/nmr_staging/spectral_matrices/MTBLS1_1r_noesypr1d_spectralMatrix.RDS<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Filepath to the .RDS spectral matrix file being used. On Galaxy, this can be uploaded or selected. See [specifications](https://github.com/EBI-Metabolights/SAFER-NMR/wiki/Data-processing)<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>lib.data</summary>
 <blockquote>
  /nfs/production/odonovan/nmr_staging/gissmo_ref/data.list_700MHz.RDS<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Library reference spectra files. See [specifications](https://github.com/EBI-Metabolights/SAFER-NMR/wiki/Reference-Library-Data)<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  File information for pipeline inputs<br>
 </blockquote>
 </details>
</blockquote>
</details>

<details>
<summary>corrpockets</summary>
<blockquote>
 <details>
 <summary>half.window</summary>
 <blockquote>
  0.06<br>
  <details>
  <summary>description</summary>
  <blockquote>
   1/2 initial tolerance for resonance pairs; this is in PPM<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>noise.percentile</summary>
 <blockquote>
  0.99<br>
  <details>
  <summary>description</summary>
  <blockquote>
   type of noise cutoff; higher is looser (more noise). <br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>only.region.between</summary>
 <blockquote>
  - -1.0 <br>
  - 11.0 <br>

  <details>
  <summary>description</summary>
  <blockquote>
   only run corrpocketpairs on this region (e.g. c(-1, 11) - not necessary, but only protofeatures in this region will be STORM'd<br>
   The bounds can be written on one line as:<br>
    !expr c(-1, 11)<br>
   or on two in this form:<br>
    - -1<br>
    - 11<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>rcutoff</summary>
 <blockquote>
  0.5<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Pearson correlation coefficient (r) cutoff for considering correlation peaks in protofeature extraction. <br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  Protofeature generation parameters. These can be set relatively permissively. See [algorithm details](https://github.com/EBI-Metabolights/SAFER-NMR/wiki/How-FSE-works)<br>
 </blockquote>
 </details>
</blockquote>
</details>

<details>
<summary>storm</summary>
<blockquote>
 <details>
 <summary>correlation.r.cutoff</summary>
 <blockquote>
  0.7<br>
  <details>
  <summary>description</summary>
  <blockquote>
   correlation cutoff (for both subset and profile refinement steps in LOG-STORM)<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>q</summary>
 <blockquote>
  0.01<br>
  <details>
  <summary>description</summary>
  <blockquote>
   STORM adjusted pvalue <br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>b</summary>
 <blockquote>
  1.5<br>
  <details>
  <summary>description</summary>
  <blockquote>
   STORM b parameter - increasing opens up the search to a wider area. Units: peak widths<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>number.of.plots</summary>
 <blockquote>
  250<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Plots are typically not generated - deprecated parameter!<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  Parameters for LOG-STORM. See details about the algorithm [here]()<br>
 </blockquote>
 </details>
</blockquote>
</details>

<details>
<summary>tina</summary>
<blockquote>
 <details>
 <summary>bounds</summary>
 <blockquote>
  -1<br>
  11<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Features outside of these boundaries (ppm units) will be discarded before matching. <br>
   The bounds can be written on one line as:<br>
   !expr c(-1, 11)<br>
   or on two in this form:<br>
    - -1<br>
    - 11<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>min.subset</summary>
 <blockquote>
  5<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Minimum number of spectra in which a feature must be found to be included. Usually set to 4-5, must be > 3 (or else correlations are not really meaningful)<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>prom.ratio</summary>
 <blockquote>
  0.3<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Prominence ratio - in order to detect strong local baseline effects in feature shapes, at least one peak must have prominence > prom.ratio * range(feature.intensities). <br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>do.clustering</summary>
 <blockquote>
  FALSE<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Should clustering be attempted to reduce feature shape duplication? Not recommended at present. If used, OPTICS clustering will be employed.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>clustering</summary>
 <blockquote>
  <details>
  <summary>max.eps</summary>
  <blockquote>
   50<br>
   <details>
   <summary>description</summary>
   <blockquote>
    description<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>minPts</summary>
  <blockquote>
   2<br>
   <details>
   <summary>description</summary>
   <blockquote>
    description<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>eps.stepsize</summary>
  <blockquote>
   0.01<br>
   <details>
   <summary>description</summary>
   <blockquote>
    description<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>description</summary>
  <blockquote>
   Parameters for OPTICS clustering of feature shapes. Clustering can be used to reduce matching computations. However, matching scales better now, and this is not necessary and can introduce undesirable effects.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>plots</summary>
 <blockquote>
  <details>
  <summary>max.plots</summary>
  <blockquote>
   600<br>
   <details>
   <summary>description</summary>
   <blockquote>
    description<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>filtered.out</summary>
  <blockquote>
   TRUE<br>
   <details>
   <summary>description</summary>
   <blockquote>
    description<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>filtered.features</summary>
  <blockquote>
   TRUE<br>
   <details>
   <summary>description</summary>
   <blockquote>
    description<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>cleaned.clusters</summary>
  <blockquote>
   TRUE<br>
   <details>
   <summary>description</summary>
   <blockquote>
    description<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>description</summary>
  <blockquote>
   Whether or not certain sets of plots should be generated. Can help with troubleshooting.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  Parameters for TINA (TINA Is Not Alignment). This was initially a script for feature de-duplication and combination into clusters, but that is unnecessary as reference matching effectively accomplishes this. Now, since matching scales well, it's more about filtering features and spec-feature extraction (identifying features across spectra).<br>
 </blockquote>
 </details>
</blockquote>
</details>

<details>
<summary>matching</summary>
<blockquote>
 <details>
 <summary>cluster.profile</summary>
 <blockquote>
  representative.feature<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Not currently in use (leave set to 'representative.feature'. If clustering is done, this determines whether a representative feature shape is used for matching, or whether the weighted.mean of the cluster is used as the shape to match. <br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>ref.sig.SD.cutoff</summary>
 <blockquote>
  0.01<br>
  <details>
  <summary>description</summary>
  <blockquote>
   When interpolating reference spectra, it is useful to filter out very low spectral regions in order to compress the reference data matrix. This parameter controls that cutoff, defined in multiples of the whole-spectrum standard deviation. It only needs to be a rough approximation as most useful shape matching information tends to be higher signal. Exercise caution if real PCRSs are used, but imperfect settings shouldn't affect results too much.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>max.hits</summary>
 <blockquote>
  5<br>
  <details>
  <summary>description</summary>
  <blockquote>
   During matching, only the top _max.hits_ convolution peaks between each feature and ref spectrum (fast proxy for cross correlation lags) are assessed for Pearson Correlation Coefficient (r). This should be high enough to allow for several local optima (e.g. 3-5).<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>r.thresh</summary>
 <blockquote>
  0.8<br>
  <details>
  <summary>description</summary>
  <blockquote>
   The top _max.hits_ convolution peaks are assessed for Pearson's r. If any matches between the  are lower than this, they are excluded. Note: backfits (matches back to dataset spectra) are limited, so the effective _r.thresh_ may change as a result of jettisoning matches to satisfy that cutoff (_max.backfits_)<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>p.thresh</summary>
 <blockquote>
  0.01<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Adjusted p-value cutoff for cross-correlations (as defined for STORM).<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>filtering</summary>
 <blockquote>
  <details>
  <summary>res.area.threshold</summary>
  <blockquote>
   0.25<br>
   <details>
   <summary>description</summary>
   <blockquote>
    What fraction of a matched resonance (peak) in the reference dataset must be accounted for by a fit feature to be considered 'matched'?<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>ppm.tol</summary>
  <blockquote>
   0.1<br>
   <details>
   <summary>description</summary>
   <blockquote>
    How far away (+/- ppm) can the center of a match be in the dataset from the matched point on the reference spectrum?<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>max.backfits</summary>
  <blockquote>
   1e+08<br>
   <details>
   <summary>description</summary>
   <blockquote>
    Upper limit to the number of ref-features that can be back-fitted to the dataset spectra from which the corresponding feature was extracted?<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>select</summary>
  <blockquote>
   random<br>
   <details>
   <summary>description</summary>
   <blockquote>
    If backfits need to be limited, matches must be discarded. Should they be discarded at 'random', or should higher r-value matches be prioritized ('rval')?<br>
   </blockquote>
   </details>
  </blockquote>
  </details>

  <details>
  <summary>description</summary>
  <blockquote>
   match filtering parameters<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  Parameters for matching to PCRSs (reference spectra). More info on [matching]()<br>
 </blockquote>
 </details>
</blockquote>
</details>

<details>
<summary>par</summary>
<blockquote>
 <details>
 <summary>ncores</summary>
 <blockquote>
  48<br>
  <details>
  <summary>description</summary>
  <blockquote>
   number of cores to use for computations. It's best to leave a few extra cores on personal machines. Be careful about RAM (expect to use 5-10Gb per core).<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>type</summary>
 <blockquote>
  FORK<br>
  <details>
  <summary>description</summary>
  <blockquote>
   what type of parallel process ("FORK" or "PSOCK"; see parallel::makeCluster documentation). Most parallel operations have now been converted to mclapply, so this primarily affects the matching loops.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  Parallel computing parameters.<br>
 </blockquote>
 </details>
</blockquote>
</details>

<details>
<summary>galaxy</summary>
<blockquote>
 <details>
 <summary>enabled</summary>
 <blockquote>
  FALSE<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Is this going to be run on a Galaxy environment? If so, certain pipeline operations need to change, and this switch will trigger those.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  description<br>
 </blockquote>
 </details>
</blockquote>
</details>

<details>
<summary>debug</summary>
<blockquote>
 <details>
 <summary>enabled</summary>
 <blockquote>
  FALSE<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Run in debug mode? This is necessary to throttle features (see below).<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>throttle_features</summary>
 <blockquote>
  100<br>
  <details>
  <summary>description</summary>
  <blockquote>
   How many features (1:n) should be used for matching? This can keep runs short, but can also result in no matches if very small numbers are used.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>all.outputs</summary>
 <blockquote>
  TRUE<br>
  <details>
  <summary>description</summary>
  <blockquote>
   Should intermediate outputs be written to a debug directory? These will be zipped if so.<br>
  </blockquote>
  </details>
 </blockquote>
 </details>

 <details>
 <summary>description</summary>
 <blockquote>
  things useful for debugging<br>
 </blockquote>
 </details>
</blockquote>
</details>


