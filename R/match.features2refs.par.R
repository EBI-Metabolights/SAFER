#' Match STORM features to GISSMO database using parallel computing
#'
#' This function matches STORM'd feature shapes to a reference database using cross-correlation,
#' least-squares fitting, and peak quality weighting. The matching process is parallelized
#' for speed, and results are saved as an RDS file. The function reads in parameters from
#' a YAML file and data from RDS files generated by previous function calls (from fse() and tina())
#'
#' Matching:
#' Matching is accomplished by cross-correlating all pairwise feature - reference
#' spectrum pairs. Since there are feature-level comparisons to make (i.e. a single
#' feature across all matches), iteration over features is serial. Iteration over
#' references for each feature is done in parallel. This comparison is not optimal,
#' but works as a proof of concept and can be scaled up. Increasing numbers of
#' features results in a linear increase in computational time, but also more memory
#' usage for each core. Generally, it is advisable to leave 1 or 2 cores on one's
#' machine free for system operations and the main R instance. For each comparison
#' that is, for each feature - reference pair being tested, the top max.hits
#' (e.g., 5) convolution hits are assessed for pearson correlation coefficient
#' (r.thresh) and pvalue (p.thresh). For hits passing both thresholds, the feature
#' is fit to the reference using least squares. RMSE is reported.
#'
#' Next, it's best to avoid penalizing a feature fit just because it contains false
#' positive points. Once a feature has been fit to all reference spectra (at 0-5
#' more places), resonances which were never fit are identified using peak poorness:
#' 1) Line up all fits for that feature across the database.
#' 2) For each fit, take the positive residuals, divide by feature intensity. If
#'    values are close to 1, the feature was completely absent in the ref
#'    signature at those point. This is a measure of ~ peak poorness for this database
#' 3) Take the mean of those values across all fits for each point in the feature.
#' 4) Square peak-poorness to squash them down unless very high:
#'     peak.quality = 1-(peak.poorness^2)
#' 5) For each fit's non-missing values:
#'     rmse.weighted = sum(residuals * peak.quality)/n.points
#'
#' This metric appears to give more intuitive results. Missing reference resonances
#' compared to the feature is preferable to the opposite, which will be measured
#' during backfitting.
#' Matches are written to file.
#' Note: matching in parallel is much lighter (~50%) if run in a new R instance
#' outside of RStudio due to memory leaks/overhead.
#'
#' @param pars a list of parameters for matching, read in from a YAML file
#' @return nothing; results are saved as an RDS file
#' @importFrom matrixStats rowMins
#' @importFrom doParallel registerDoParallel
#' @importFrom parallel stopCluster makeCluster
#' @importFrom foreach getDoParRegistered getDoParWorkers
#' @importFrom magrittr %>%
#' @importFrom pbapply pbapply
#' @importFrom fftw FFT
#' @importFrom stats cor
#' @importFrom graphics plot
#' @importFrom ggplot2 ggplot geom_point geom_smooth aes
#' @importFrom reshape2 melt
#' @importFrom dplyr mutate
#' @importFrom data.table rbindlist
#' @importFrom scales alpha
#' @importFrom fpc cluster.stats
#' @importFrom stringr str_c
#' @export
match.features2refs.par <- function(pars) {
  message("-------------------------------------------------------")
  message("-------------------     Matching    -------------------")
  message("-------------------------------------------------------")
  message("\n\n\n")


  tmpdir <- pars$dirs$temp
  this.run <- paste0(tmpdir)

  ##################################################################################################################
  # Read data and set up ####
  message("### Matching STORM features to GISSMO database")
  message("### MTJ 2023")
  message("")
  message("Loading data from files...\n\n\n")

  fse.result <- readRDS(paste0(this.run, "/fse.result.RDS"))
  clusters <- readRDS(paste0(this.run, "/clusters.RDS"))
  feature <- readRDS(paste0(this.run, "/feature.RDS"))

  ##################################################################################################################

  ## Ref data import ####
  message("Loading and processing reference spectrum data...\n")
  lib.info <- readRDS(paste0(this.run, "/lib.info.RDS"))


  # Import and process the spectra for this dataset ####

  lib.data <- readRDS(paste0(this.run, "/lib.data.RDS"))
  message(" - interpolating ref data to study ppm axis...\n\n")
  lib.data.processed <- prepRefs.for.dataset(lib.data,
    ppm.dataset = fse.result$ppm,
    ref.sig.SD.cutoff = pars$matching$ref.sig.SD.cutoff
  )
  rm(lib.data)
  saveRDS(lib.data.processed, paste0(this.run, "/lib.data.processed.RDS"))

  ##################################################################################################################


  # Setup ####

  # Put features in a matrix
    if (pars$debug$enabled == TRUE) {
      rand.ids <- runif(n = pars$debug$throttle_matches, 
                        min = 1, 
                        max = length(unique(clusters$cluster.labs))) %>% round %>% unique
      f.subset <- lapply(unique(clusters$cluster.labs), function(x) {
        (clusters$cluster.labs == x) %>%
          which() %>% .[1]
      }) %>%
        unlist() %>% .[rand.ids]
    } else {
          f.subset <- lapply(unique(clusters$cluster.labs), function(x) {
        (clusters$cluster.labs == x) %>%
          which() %>% .[1]
      }) %>% unlist()
    }

  f.stack <- feature$stack[f.subset, , drop = F]
  f.position <- feature$position[f.subset, , drop = F]

  # Put ref spectra in a matrix
  ref.mat <- lapply(
    lib.data.processed,
    function(x) x$mapped$data
  ) %>%
    do.call(rbind, .)

  # Clean up heavy objects
  rm(lib.data.processed)

  # Pre-compute fts for features and refs ####
  message("Pre-computing fts for features and refs (will take a minute)...\n\n\n")
  # Pad size for ref needs to be max.length(features)

  pad.size <- f.stack %>% ncol() - 1

  # Ref mat (padded)
  ref.mat.p <- ref.mat %>% padmat(use = 0, col.by = pad.size)
  ref.mat.p[is.na(ref.mat.p)] <- 0

  # Make padded feature matrix
  # Matrix of zeros of size (refs)

  f.stack <- f.stack - matrixStats::rowMins(f.stack, na.rm = T)
  # f.stack[is.na(f.stack)] <- 0
  f.mat <- matrix(0, nrow = nrow(f.stack), ncol = ncol(ref.mat.p))

  # Get the positions of each feature in feature matrix, with rows = feature number
  coords <- which(!is.na(f.stack), arr.ind = T)

  # Linear index the feature vals in
  li <- sub2indR(rows = coords[, "row"], cols = coords[, "col"], m = nrow(f.mat))
  f.mat[li] <- f.stack[li]

  # Loop through feature matrix, compute Conj(fftw::fft())
  # f.mat <- apply(f.mat, 1, function(f) Conj(fftw::FFT(f)))
  f.mat <- apply(f.mat, 1, function(f) Conj(fftw::FFT(f))) %>% t()

  # Loop through spec matrix, compute fftw::fft()
  r.mat <- apply(ref.mat.p, 1, function(r) fftw::FFT(r)) %>% t()

  # Transpose matrices (to work with do, dopar) ####
  message("Transposing feature and reference matrices (takes a few seconds)...\n\n")
  f.mat <- t(f.mat)
  r.mat <- t(r.mat)
  f.stack <- t(f.stack)
  ref.mat <- t(ref.mat)

  ############ Match each feature to refs - v2 - "Par"ty time ####
  # # For each feature:
  # # - find top 5 convolution peaks
  # #   - calculate their PCCs (with NAs)
  # #   - filter for rval and pval
  # # - calculate least-squares fit for each passing match position
  # #   - get scores, residuals
  # #   - calc rmse
  # # - identify parts of feature which never match any reference
  # #     (likely FP, or not useful in this DB)
  # #   - convert to peak quality vector for feature
  # #   - recalculate rmse using residuals weighted by peak quality
  # # - storage: which match data are absolutely necessary?
  # #   - feature range match
  # #   - spectrum range match
  # #   - peak quality score vector
  # #   - single-valued metrics
  # #   - feature number
  # #   - reference number
  # #   - fit scale
  #
  # message("Matching ", nrow(f.stack), " features to ", nrow(ref.mat), " reference spectra...")



  message("Setting up parallel cluster...\n\n")

  # Par setup ####
  ncores <- pars$par$ncores
  my.cluster <- parallel::makeCluster(ncores, type = pars$par$type)
  doParallel::registerDoParallel(cl = my.cluster)
  foreach::getDoParRegistered()
  foreach::getDoParWorkers()

  # Run the matching loop ####

  t1 <- Sys.time()
  matches <- foreach(
    f.num = f.subset,
    f.ind = 1:length(f.subset), # just for
    feat = f.stack,
    feat.ft = f.mat,
    .combine = "c", .multicombine = TRUE,
    .errorhandling = "pass"
  ) %do% {
    message("Matching feature: ", f.ind, "...") # not same as f.num
    message("    - cross-correlating to refs...")
    # PARALLELIZE: Locate best positions in all available refs  ####
    allmatches.feat <- foreach(
      r.num = 1:ncol(r.mat),
      ref = ref.mat,
      ref.ft = r.mat,
      .combine = "rbind", .packages = "fftw",
      .errorhandling = "pass"
    ) %dopar% {
      # Cross-correlate to find locations and scores:
      matches <- feature_match2ref_slim(f.num, r.num,
        feat, ref,
        pad.size = pad.size,
        feat.ft, ref.ft,
        max.hits = pars$matching$max.hits,
        r.thresh = pars$matching$r.thresh,
        p.thresh = pars$matching$p.thresh
      )
      # Filter out NULL values from allmatches.feat
      matches <- allmatches.feat[!is.null(allmatches.feat)]
      return(matches)
    }

    # Escape and return nothing if there are no matches to evaluate: ####
    if (nrow(allmatches.feat) == 0) {
      return(list(
        matches = NA,
        peak.quality = NA,
        fits = NA
      ))
    }

    ######################################################################

    # Evaluate fits for top-scoring positions (regardless of ref) ####
    message("    - calculating fits...")

    allmatches.fits <- lapply(1:nrow(allmatches.feat), function(m) {

      # Get f and r indices for this row
      f <- allmatches.feat[m, "feat"]
      r <- allmatches.feat[m, "ref"]
      feat.pos <- allmatches.feat[m, c("feat.start", "feat.end")] %>%
        as.numeric() %>%
        fillbetween()
      ref.pos <- allmatches.feat[m, c("ref.start", "ref.end")] %>%
        as.numeric() %>%
        fillbetween()

      # Get spectral signatures which matched
      ref <- ref.mat[, r, drop = F]

      # Fit
      fit <- fit.leastSquares(feat[feat.pos], ref[ref.pos], plots = F)
      # fit$plot
      fit$wasserstein.score <- score.wasserstein(fit$feat.fit, fit$spec.fit)

      return(fit)
    })

    # Extract out minimal fit data ####
    fit.data <- lapply(allmatches.fits, function(f) f$fit %>% as.numeric()) %>% do.call(rbind, .)
    allmatches.feat[, "fit.intercept"] <- fit.data[, 1]
    allmatches.feat[, "fit.scale"] <- fit.data[, 2]

    # Add some different scores from the fits ####
    message("    - calculating additional scores...")
    allmatches.feat[, "wasserstein.score"] <-
      lapply(allmatches.fits, function(x) x$wasserstein.score) %>% unlist()
    allmatches.feat[, "sum.residuals"] <-
      lapply(allmatches.fits, function(x) x$sum.residuals) %>% unlist()
    allmatches.feat[, "rmse"] <-
      lapply(allmatches.fits, function(x) x$rmse) %>% unlist()

    # Need to guarantee that the fits all have values

    # Re-weight the rmses using peak quality (for this db) ####
    message("    - estimating peak quality, weighting RMSEs...\n")
    peak.poorness <- bad.peaks(
      pos.res.pct.feat = lapply(
        allmatches.fits,
        function(x) x$overshoot.pct.feat
      ) %>% do.call(rbind, .),
      scale.exp = 2
    )
    allmatches.feat[, "rmse.weighted"] <- lapply(1:nrow(allmatches.feat), function(m) {
      match <- allmatches.fits[[m]]
      v1 <- match$feat.fit
      v2 <- match$spec.fit
      resids <- v1 - v2
      use <- !is.na(resids + peak.poorness)
      rmse <- sum((resids[use] * (1 - peak.poorness[use]))^2) / sum(use)
      return(rmse)
    }) %>% unlist()

    # Ditch singlet-only fits, or they will fit everything and dominate!
    # If the ref in any fit has only a singlet fit, then throw it away.
    # How can this be known?

    # Format results ####

    return(list(
      matches = allmatches.feat,
      peak.quality = peak.poorness,
      fits = allmatches.fits
    ))
  }
  print(Sys.time() - t1)

  parallel::autoStopCluster(my.cluster)


  ############ Format results and save ########################################################################################
  # Compile and save match results ####
  message("Saving match results...\n\n\n")
  saveRDS(matches, paste0(this.run, "/matches.RDS"))


  message("-------------------------------------------------------")
  message("-----------------  Matching Complete ------------------")
  message("-------------------------------------------------------")
}
